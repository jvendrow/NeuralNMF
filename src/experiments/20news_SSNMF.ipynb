{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "\n",
    "from ssnmf import SSNMF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing 20 Newsgroup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ('headers','footers','quotes')\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['thanks','edu','also','would','one','could','please','really','many','anyone','good','right','get','even','want','must','something','well','much','still','said','stay','away','first','looking','things','try','take','look','make','may','include','thing','like','two','or','etc','phone','oh','email'])\n",
    "\n",
    "\n",
    "categories = [\n",
    " 'comp.graphics',\n",
    "\n",
    " 'comp.sys.mac.hardware',\n",
    " 'misc.forsale',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.religion.misc'\n",
    " ]\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "\n",
    "# remove numbers\n",
    "data_cleaned = [re.sub(r'\\d+','', file) for file in newsgroups_train.data]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
    "vectors = vectorizer.fit_transform(data_cleaned).transpose()\n",
    "idx_to_word = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "X = vectors\n",
    "d, n = np.shape(X)\n",
    "Y = np.zeros((n))\n",
    "\n",
    "labels = {0:0, 1:0, 2:1, 3:2, 4:2, 5:3, 6:3, 7:4, 8:4, 9:5}\n",
    "\n",
    "for i in range(n-1):\n",
    "    label = newsgroups_train.target[i]\n",
    "    Y[i] = label\n",
    "\n",
    "X = torch.from_numpy(X.todense())\n",
    "Y = torch.from_numpy(Y).long()\n",
    "\n",
    "\n",
    "m = X.shape[0]\n",
    "k1 = 10\n",
    "k2 = 6\n",
    "\n",
    "sub = 100 #HOW MANY PER CLASS\n",
    "count = np.zeros((k1))\n",
    "\n",
    "X_new = torch.zeros((X.shape[0], sub*k1))\n",
    "Y_new = torch.zeros((sub*k1)).long()\n",
    "Y_10 = torch.zeros((sub*k1)).long()\n",
    "j = 0\n",
    "for i in range(Y.shape[0]):\n",
    "    if(count[Y[i]] >= sub):\n",
    "        continue\n",
    "    count[Y[i]] += 1\n",
    "    X_new[:,j] = X[:,i]\n",
    "    Y_new[j] = labels[int(Y[i])]\n",
    "    Y_10[j] = int(Y[i])\n",
    "    j += 1\n",
    "\n",
    "X = X_new\n",
    "Y = Y_new\n",
    "\n",
    "ind = np.argsort(Y_10)\n",
    "X = X[:,ind]\n",
    "Y = Y[ind]\n",
    "Y_10 = Y_10[ind]\n",
    "\n",
    "split = 0.75\n",
    "L = np.zeros((6, Y.shape[0]))\n",
    "for i in range(10):\n",
    "    L[:,i*sub:i*sub+(int(split*sub))] = 1\n",
    "\n",
    "X = np.asarray(X)\n",
    "Y = np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_hot = np.zeros((Y.shape[0], Y.max()+1))\n",
    "Y_hot[np.arange(Y.shape[0]),Y] = 1\n",
    "Y_hot = Y_hot.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run First layer of Unsupervised NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with run...    1\n",
      "Done with run...    2\n",
      "Done with run...    3\n",
      "Done with run...    4\n",
      "Done with run...    5\n",
      "Done with run...    6\n",
      "Done with run...    7\n",
      "Done with run...    8\n",
      "Done with run...    9\n",
      "Done with run...    10\n"
     ]
    }
   ],
   "source": [
    "results_all_layer_1 = []\n",
    "results_all_layer_2_unsup = []\n",
    "results_all_layer_2_sup = []\n",
    "\n",
    "for i in range(0,10):\n",
    "    \n",
    "    \n",
    "    # Run First Layer of Unsupervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_1 = SSNMF(X,10,modelNum=1)\n",
    "    N = 800\n",
    "    model_1.mult(numiters = N)\n",
    "\n",
    "    results_layer_1 = {}\n",
    "    results_layer_1['A'] = model_1.A\n",
    "    results_layer_1['S'] = model_1.S\n",
    "    results_all_layer_1.append(results_layer_1)\n",
    "    \n",
    "    \n",
    "    # Run Second Layer of Unsupervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_2 = SSNMF(model_1.S,6,modelNum=1)\n",
    "    N = 800\n",
    "    model_2.mult(numiters = N)\n",
    "    \n",
    "    results_layer_2_unsup = {}\n",
    "    results_layer_2_unsup['A'] = model_2.A\n",
    "    results_layer_2_unsup['S'] = model_2.S\n",
    "    results_all_layer_2_unsup.append(results_layer_2_unsup)\n",
    "    \n",
    "    \n",
    "    # Run Second Layer of Supervised NMF\n",
    "    # ------------------------------------\n",
    "    \n",
    "    np.random.seed(i)\n",
    "    model_3 = SSNMF(model_1.S,6,Y = Y_hot,L=L,lam=15, modelNum=3)\n",
    "    N = 800\n",
    "    model_3.mult(numiters = N)\n",
    "    \n",
    "    results_layer_2_sup = {}\n",
    "    results_layer_2_sup['A'] = model_3.A\n",
    "    results_layer_2_sup['S'] = model_3.S\n",
    "    results_all_layer_2_sup.append(results_layer_2_sup)\n",
    "    \n",
    "    print(\"Done with run...   \", i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_all_layer_1 = []\n",
    "acc_all_layer_2_unsup = []\n",
    "acc_all_layer_2_sup = []\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    \n",
    "    results_layer_1 = results_all_layer_1[i]\n",
    "    results_layer_2_unsup = results_all_layer_2_unsup[i]\n",
    "    results_layer_2_sup = results_all_layer_2_sup[i]\n",
    "    \n",
    "    B = np.multiply(Y_hot,L) @ np.linalg.pinv(results_layer_1['S'])\n",
    "    Y_pred = np.argmax(np.dot(B,results_layer_1['S']), axis=0)\n",
    "    acc = Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0] / Y[L[0]==0].shape[0]\n",
    "    acc_all_layer_1.append(acc)\n",
    "    \n",
    "    B = np.multiply(Y_hot,L) @ np.linalg.pinv(results_layer_2_unsup['S'])\n",
    "    Y_pred = np.argmax(np.dot(B,results_layer_2_unsup['S']), axis=0)\n",
    "    acc = Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0] / Y[L[0]==0].shape[0]\n",
    "    acc_all_layer_2_unsup.append(acc)\n",
    "    \n",
    "    B = np.multiply(Y_hot,L) @ np.linalg.pinv(results_layer_2_sup['S'])\n",
    "    Y_pred = np.argmax(np.dot(B,results_layer_2_sup['S']), axis=0)\n",
    "    acc = Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0] / Y[L[0]==0].shape[0]\n",
    "    acc_all_layer_2_sup.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 unsupervised accuracy...   0.5932000000000001\n",
      "Layer 2 unsupervised accuracy...   0.5071999999999999\n",
      "Layer 2 supervised accuracy...   0.546\n"
     ]
    }
   ],
   "source": [
    "print(\"Layer 1 unsupervised accuracy...  \", sum(acc_all_layer_1) / 10)\n",
    "print(\"Layer 2 unsupervised accuracy...  \", sum(acc_all_layer_2_unsup) / 10)\n",
    "print(\"Layer 2 supervised accuracy...  \", sum(acc_all_layer_2_sup) / 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_0 = model_1.A\n",
    "S_1 = model_1.S\n",
    "\n",
    "B = np.multiply(Y_hot,L) @ np.linalg.pinv(S_1)\n",
    "\n",
    "Y_pred = np.argmax(np.dot(B,S_1), axis=0)\n",
    "\n",
    "#Y = Y.numpy()\n",
    "print(\"Accuracy: {}/{}\".format(Y[Y_pred==Y].shape[0], Y.shape[0]))\n",
    "print(\"Accuracy: {}/{}\".format(Y[L[0]==1][Y_pred[L[0]==1]==Y[L[0]==1]].shape[0], Y[L[0]==1].shape[0]))\n",
    "print(\"Accuracy: {}/{}\".format(Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0], Y[L[0]==0].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Second Layer of Unsupervised NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "\n",
    "model_2 = SSNMF(S_1,6,modelNum=1)\n",
    "\n",
    "N=3000\n",
    "model_2.mult(numiters = N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_1 = model_2.A\n",
    "S_2 = model_2.S\n",
    "\n",
    "B = np.multiply(Y_hot,L) @ np.linalg.pinv(S_2)\n",
    "\n",
    "Y_pred = np.argmax(np.dot(B,S_2), axis=0)\n",
    "\n",
    "#Y = Y.numpy()\n",
    "print(\"Accuracy: {}/{}\".format(Y[Y_pred==Y].shape[0], Y.shape[0]))\n",
    "print(\"Accuracy: {}/{}\".format(Y[L[0]==1][Y_pred[L[0]==1]==Y[L[0]==1]].shape[0], Y[L[0]==1].shape[0]))\n",
    "print(\"Accuracy: {}/{}\".format(Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0], Y[L[0]==0].shape[0]))\n",
    "\n",
    "Y_10 = np.asarray(Y_10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Second Layer of Supervised NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = SSNMF(S_1,6,Y = np.multiply(Y_hot,L),L=L,lam=1000, modelNum=3)\n",
    "np.random.seed(1)\n",
    "\n",
    "model_3 = SSNMF(S_1,6,Y = Y_hot,L=L,lam=15, modelNum=3)\n",
    "\n",
    "N=3000\n",
    "model_3.mult(numiters = N)\n",
    "A_1 = model_3.A\n",
    "S_2 = model_3.S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = model.B\n",
    "\n",
    "Y_pred = np.argmax(np.dot(B,S_2), axis=0)\n",
    "Y = np.asarray(Y)\n",
    "\n",
    "print(\"Accuracy:          {}/{}\".format(Y[Y_pred==Y].shape[0], Y.shape[0]))\n",
    "print(\"Accuracy known:    {}/{}\".format(Y[L[0]==1][Y_pred[L[0]==1]==Y[L[0]==1]].shape[0], Y[L[0]==1].shape[0]))\n",
    "print(\"Accuracy unknown:  {}/{}\".format(Y[L[0]==0][Y_pred[L[0]==0]==Y[L[0]==0]].shape[0], Y[L[0]==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = A_0\n",
    "A2 = A_1\n",
    "\n",
    "keywords = np.empty((12,10), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "for i in range(A1.shape[1]):\n",
    "    col = A1[:,i]\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][: :-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 10 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(0,5)))\n",
    "print(\"\")\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(5,10)))\n",
    "\n",
    "\n",
    "keywords = np.empty((12,6), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "A = A1 @ A2\n",
    "for i in range(A.shape[1]):\n",
    "    col = A[:,i]\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][::-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 6 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate reconstruction error\n",
    "layer1_error = np.linalg.norm(X - A_0 @ S_1)\n",
    "layer2_error = np.linalg.norm(X - A_0 @ A_1 @ S_2)\n",
    "\n",
    "print(\"Layer 1 error...    \" + str(layer1_error))\n",
    "print(\"Layer 2 error...    \" + str(layer2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = A_0\n",
    "A2 = A_1\n",
    "\n",
    "keywords = np.empty((12,10), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "for i in range(A1.shape[1]):\n",
    "    col = A1[:,i]*7/6 -  np.mean(A1, axis=1)\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][::-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 10 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(0,5)))\n",
    "print(\"\")\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(5,10)))\n",
    "\n",
    "\n",
    "keywords = np.empty((12,6), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "A = A1 @ A2\n",
    "for i in range(A.shape[1]):\n",
    "    col = A[:,i]*7/6 - np.mean(A,axis=1)\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][::-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 6 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
