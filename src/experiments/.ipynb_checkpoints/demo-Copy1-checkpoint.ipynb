{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This demo demonstrate how to train various (semi-supervised) Neural NMF models and how to analyze and visualize the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'train_supervised_direct' from 'neural_nmf' (../neural_nmf/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d5642ab4d4bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_nmf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNeural_NMF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEnergy_Loss_Func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mL21_Norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRecon_Loss_Func\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_nmf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLsqNonneg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mneural_nmf\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_supervised\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_supervised_direct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'train_supervised_direct' from 'neural_nmf' (../neural_nmf/__init__.py)"
     ]
    }
   ],
   "source": [
    "# loading packages and functions\n",
    "import torch\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "#import Ipynb_importer\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../src')\n",
    "sys.path.insert(1, '../')\n",
    "#from neural_nmf import Neural_NMF, Energy_Loss_Func, L21_Norm, Recon_Loss_Func\n",
    "#from lsqnonneg_module import LsqNonneg\n",
    "#from train import train_unsupervised, train_supervised\n",
    "#from writer import Writer\n",
    "from neural_nmf import Neural_NMF, Energy_Loss_Func, L21_Norm, Recon_Loss_Func\n",
    "from neural_nmf import LsqNonneg\n",
    "from neural_nmf import train_unsupervised, train_supervised, train_supervised_direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loading \n",
    "data = scipy.io.loadmat('synthetic_noise.mat')\n",
    "X = data['X']\n",
    "X = Variable(torch.from_numpy(X).double())\n",
    "Y2 = data['Y2']\n",
    "Y2 = Variable(torch.from_numpy(Y2).double())\n",
    "Y4 = data['Y4']\n",
    "Y4 = Variable(torch.from_numpy(Y4).double())\n",
    "Y9 = data['Y9']\n",
    "Y9 = Variable(torch.from_numpy(Y9).double())\n",
    "L0 = data['L0']\n",
    "L0 = Variable(torch.from_numpy(L0).double())\n",
    "L10 = data['L10']\n",
    "L10 = Variable(torch.from_numpy(L10).double())\n",
    "L20 = data['L20']\n",
    "L20 = Variable(torch.from_numpy(L20).double())\n",
    "L30 = data['L30']\n",
    "L30 = Variable(torch.from_numpy(L30).double())\n",
    "L40 = data['L40']\n",
    "L40 = Variable(torch.from_numpy(L40).double())\n",
    "L50 = data['L50']\n",
    "L50 = Variable(torch.from_numpy(L50).double())\n",
    "L60 = data['L60']\n",
    "L60 = Variable(torch.from_numpy(L60).double())\n",
    "L70 = data['L70']\n",
    "L70 = Variable(torch.from_numpy(L70).double())\n",
    "L80 = data['L80']\n",
    "L80 = Variable(torch.from_numpy(L80).double())\n",
    "L90 = data['L90']\n",
    "L90 = Variable(torch.from_numpy(L90).double())\n",
    "labels9 = data['labels9']\n",
    "labels9 = Variable(torch.from_numpy(labels9).long())\n",
    "labels9 = torch.reshape(labels9,[90])\n",
    "labels4 = data['labels4']\n",
    "labels4 = Variable(torch.from_numpy(labels4).long())\n",
    "labels4 = torch.reshape(labels4,[90])\n",
    "labels2 = data['labels2']\n",
    "labels2 = Variable(torch.from_numpy(labels2).long())\n",
    "labels2 = torch.reshape(labels2,[90])\n",
    "plt.imshow(X,aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(Y2,aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(Y4,aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the network parameters\n",
    "m = X.shape[0]\n",
    "k1 = 9\n",
    "k2 = 4\n",
    "k3 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised One-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_NMF([m, k1])\n",
    "loss_func = Energy_Loss_Func()\n",
    "X_input = X\n",
    "history_unsupervised = train_unsupervised(net, X_input, loss_func, epoch = 10000, lr = 1,weight_decay = 0.99,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by calling history_unsupervised.get('variable_name'), you can get the variables that you recorded in the writer\n",
    "# getting these results might be helpful for debugging and choosing hyperparameters\n",
    "A1 = history_unsupervised.get('A1')\n",
    "S1 = history_unsupervised.get('S1')\n",
    "grad_A1_lst = history_unsupervised.get('grad_A1')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_unsupervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Two-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_NMF([m, k1,k2])\n",
    "X_input = X\n",
    "history_unsupervised = train_unsupervised(net, X_input, epoch = 10000, lr = 1,weight_decay = 0.99,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by calling history_unsupervised.get('variable_name'), you can get the variables that you recorded in the writer\n",
    "# getting these results might be helpful for debugging and choosing hyperparameters\n",
    "A1 = history_unsupervised.get('A1')\n",
    "S1 = history_unsupervised.get('S1')\n",
    "grad_A1_lst = history_unsupervised.get('grad_A1')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "A2 = history_unsupervised.get('A2')\n",
    "S2 = history_unsupervised.get('S2')\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_unsupervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsupervised Three-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Neural_NMF([m, k1, k2, k3])\n",
    "loss_func = Energy_Loss_Func()\n",
    "X_input = X\n",
    "history_unsupervised = train_unsupervised(net, X_input, loss_func, epoch = 10000, lr = 1,weight_decay = 0.99,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by calling history_unsupervised.get('variable_name'), you can get the variables that you recorded in the writer\n",
    "# getting these results might be helpful for debugging and choosing hyperparameters\n",
    "A1 = history_unsupervised.get('A1')\n",
    "S1 = history_unsupervised.get('S1')\n",
    "grad_A1_lst = history_unsupervised.get('grad_A1')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "A2 = history_unsupervised.get('A2')\n",
    "S2 = history_unsupervised.get('S2')\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "A3 = history_unsupervised.get('A3')\n",
    "S3 = history_unsupervised.get('S3')\n",
    "plt.imshow(A1[-1] @ A2[-1] @ A3[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_unsupervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised One-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# supervised case\n",
    "c = 9\n",
    "net = Neural_NMF([m, k1], 9)\n",
    "net.linear.weight.data = torch.rand(c,k1,dtype = torch.double)\n",
    "loss_func = Energy_Loss_Func(lambd = 1,classification_type = 'L2')\n",
    "history_supervised = train_supervised(net, X, Y9, loss_func = loss_func, epoch = 10000, decay_epoch=100,lr_nmf = 1, lr_classification = 1, weight_decay = 1,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([87, 90])\n",
      "torch.Size([4, 90])\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y4.shape)\n",
    "print(k2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Two-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch =  100 \n",
      " tensor(0.4594, dtype=torch.float64)\n",
      "epoch =  200 \n",
      " tensor(0.3838, dtype=torch.float64)\n",
      "epoch =  300 \n",
      " tensor(0.3591, dtype=torch.float64)\n",
      "epoch =  400 \n",
      " tensor(0.3145, dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-84df84b1acec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#net.linear.weight.data = torch.rand(c,k2,dtype = torch.double)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEnergy_Loss_Func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'L2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mhistory_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_supervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_nmf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr_classification\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecay_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfull_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/jvendrow/Neural_NMF/src/neural_nmf/train.py\u001b[0m in \u001b[0;36mtrain_supervised\u001b[0;34m(net, X, label, L, loss_func, epoch, lr_nmf, lr_classification, weight_decay, class_iters, decay_epoch, initialize_support, optimizer, verbose, verbose_epoch, full_history)\u001b[0m\n\u001b[1;32m    339\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0miter_classifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_iters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m             \u001b[0mS_lst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pred'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/Neural_NMF/src/neural_nmf/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, last_S_lst)\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast_S_lst\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Calculates the least squares objective S = min S>=0 ||X - AS||\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_S_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Calculates the least squares objective S = min S>=0 ||X - AS||\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/Neural_NMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, last_S)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLsqNonnegF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/Neural_NMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, A, last_S)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsqnonneg_tensor_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/Neural_NMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mlsqnonneg_tensor_version\u001b[0;34m(A, X, last_S)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m#[s, res] = nnls(A, x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnnls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0;31m#[s, res] = fnnls(A, x, P_initial=P_initial)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jvendrow/.local/lib/python3.6/site-packages/fnnls/fnnls.py\u001b[0m in \u001b[0;36mfnnls\u001b[0;34m(Z, x, P_initial, lstsq)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;31m#B4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstsq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mZTZ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mZTx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;31m#C1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "c = 4\n",
    "net = Neural_NMF([m, k1, k2], 4)\n",
    "#net.linear.weight.data = torch.rand(c,k2,dtype = torch.double)\n",
    "loss_func = Energy_Loss_Func(lambd = 1,classification_type = 'L2')\n",
    "history_supervised = train_supervised(net, X, Y4, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=100,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Three-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "net = Neural_NMF([m, k1, k2, k3], c)\n",
    "loss_func = Energy_Loss_Func(lambd = 1,classification_type = 'L2')\n",
    "history_supervised = train_supervised(net, X, Y2, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "A3 = history_supervised.get('A3')\n",
    "S3 = history_supervised.get('S3')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ A3[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised One-Layer (Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervised case\n",
    "c = 9\n",
    "net = Neural_NMF([m, k1], 9)\n",
    "loss_func = Energy_Loss_Func(lambd = 1)\n",
    "history_supervised = train_supervised(net, X, labels9, loss_func = loss_func, epoch = 10000, decay_epoch=100,lr_nmf = 1, lr_classification = 1, weight_decay = 1,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Two-Layer (Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 4\n",
    "net = Neural_NMF([m, k1, k2], 4)\n",
    "loss_func = Energy_Loss_Func(lambd = 1)\n",
    "history_supervised = train_supervised(net, X, labels4, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supervised Three-Layer (Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "net = Neural_NMF([m, k1, k2, k3], c)\n",
    "loss_func = Energy_Loss_Func(lambd = 1)\n",
    "history_supervised = train_supervised(net, X, labels2, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "A3 = history_supervised.get('A3')\n",
    "S3 = history_supervised.get('S3')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ A3[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Three-Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "net = Neural_NMF([m, k1, k2, k3], c)\n",
    "loss_func = Recon_Loss_Func(lambd = 1,classification_type = 'L2')\n",
    "history_supervised = train_supervised(net, X, Y2, L=L40, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "A3 = history_supervised.get('A3')\n",
    "S3 = history_supervised.get('S3')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ A3[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(L40*Y2,aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semi-supervised Three-Layer (Cross-Entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 2\n",
    "net = Neural_NMF([m, k1, k2, k3], c)\n",
    "loss_func = Recon_Loss_Func(lambd = 1)\n",
    "history_supervised = train_supervised(net, X, labels2, L=L70, loss_func = loss_func, epoch = 10000, lr_nmf = 1, lr_classification = 1, weight_decay = 1,decay_epoch=100,verbose_epoch=1000,full_history = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = history_supervised.get('A1')\n",
    "S1 = history_supervised.get('S1')\n",
    "A2 = history_supervised.get('A2')\n",
    "S2 = history_supervised.get('S2')\n",
    "A3 = history_supervised.get('A3')\n",
    "S3 = history_supervised.get('S3')\n",
    "B = history_supervised.get('weight')\n",
    "plt.imshow(A1[-1] @ S1[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ S2[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(A1[-1] @ A2[-1] @ A3[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(B[-1] @ S3[-1],aspect='auto',cmap='binary')\n",
    "plt.show()\n",
    "plt.imshow(L70*Y2,aspect='auto',cmap='binary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the loss curve\n",
    "history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
