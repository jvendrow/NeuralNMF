{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jamiehaddock/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/experiments'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "\n",
    "from neural_nmf import Neural_NMF, Energy_Loss_Func, L21_Norm, Recon_Loss_Func\n",
    "from neural_nmf import LsqNonneg\n",
    "from neural_nmf import train_unsupervised, train_supervised\n",
    "#\n",
    "import torch.nn as nn\n",
    "from neural_nmf import Writer\n",
    "\n",
    "from time import time\n",
    "\n",
    "import re\n",
    "\n",
    "sys.path.append(\"/Users/jamiehaddock/anaconda3/lib/python3.8/site-packages\")\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preprocessing 20 Newsgroup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove = ('headers','footers','quotes')\n",
    "stopwords_list = stopwords.words('english')\n",
    "stopwords_list.extend(['thanks','edu','also','would','one','could','please','really','many','anyone','good','right','get','even','want','must','something','well','much','still','said','stay','away','first','looking','things','try','take','look','make','may','include','thing','like','two','or','etc','phone','oh','email'])\n",
    "\n",
    "categories = [\n",
    " 'comp.graphics',\n",
    " 'comp.sys.mac.hardware',\n",
    " 'misc.forsale',\n",
    " 'rec.motorcycles',\n",
    " 'rec.sport.baseball',\n",
    " 'sci.med',\n",
    " 'sci.space',\n",
    " 'talk.politics.guns',\n",
    " 'talk.politics.mideast',\n",
    " 'talk.religion.misc'\n",
    " ]\n",
    "\n",
    "\n",
    "#directory = \"categories_3\" #this was same with 50 per class\n",
    "#directory = \"categories_4\" #this is 20 per class\n",
    "directory = \"categories_5\" #this is 100 per class\n",
    "#directory = \"categories_6\" #this is 300 per class\n",
    "\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', categories=categories, remove=remove)\n",
    "\n",
    "# remove numbers\n",
    "data_cleaned = [re.sub(r'\\d+','', file) for file in newsgroups_train.data]\n",
    "\n",
    "vectorizer = TfidfVectorizer(stop_words=stopwords_list)\n",
    "vectors = vectorizer.fit_transform(data_cleaned).transpose()\n",
    "idx_to_word = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "X = vectors\n",
    "d, n = np.shape(X)\n",
    "\n",
    "Y = np.zeros((n))\n",
    "\n",
    "labels = {0:0, 1:0, 2:1, 3:2, 4:2, 5:3, 6:3, 7:4, 8:4, 9:5}\n",
    "\n",
    "for i in range(n-1):\n",
    "    label = newsgroups_train.target[i]\n",
    "    Y[i] = label\n",
    "\n",
    "X = torch.from_numpy(X.todense())\n",
    "Y = torch.from_numpy(Y).long()\n",
    "\n",
    "m = X.shape[0]\n",
    "k1 = 10\n",
    "k2 = 6\n",
    "\n",
    "\n",
    "sub = 100 #HOW MANY PER CLASS\n",
    "count = np.zeros((k1))\n",
    "\n",
    "X_new = torch.zeros((X.shape[0], sub*k1))\n",
    "Y_new = torch.zeros((sub*k1))\n",
    "j = 0\n",
    "for i in range(Y.shape[0]):\n",
    "    if(count[Y[i]] >= sub):\n",
    "        continue\n",
    "    count[Y[i]] += 1\n",
    "    X_new[:,j] = X[:,i]\n",
    "    Y_new[j] = labels[int(Y[i])]\n",
    "    j += 1\n",
    "\n",
    "X = X_new.double()\n",
    "Y = Y_new.long()\n",
    "\n",
    "ind = np.argsort(Y)\n",
    "X = X[:,ind]\n",
    "Y = Y[ind]\n",
    "\n",
    "split = 0.75\n",
    "L = torch.zeros((k2, Y.shape[0])).double()\n",
    "for i in range(len(categories)):\n",
    "    L[:,i*sub:i*sub+(int(split*sub))] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_mat = torch.zeros((6,Y.shape[0]))\n",
    "r = np.arange(Y.shape[0])\n",
    "Y_mat[[Y,r]] = 1\n",
    "Y_mat = Y_mat.double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2f4a2755fd10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNeural_NMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mhistory_supervised\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_unsupervised\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_func\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_history\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/neural_nmf/train.py\u001b[0m in \u001b[0;36mtrain_unsupervised\u001b[0;34m(net, X, loss_func, epoch, lr, weight_decay, decay_epoch, initialize_support, optimizer, verbose, verbose_epoch, full_history)\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0mS_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mS_lst\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m             \u001b[0mS_lst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_func\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamiehadd/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/neural_nmf/model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X, Y, L, last_S_lst)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepth\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlast_S_lst\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#Calculates the least squares objective S = min S>=0 ||X - AS||\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsqnonneglst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_S_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Calculates the least squares objective S = min S>=0 ||X - AS||\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jamiehadd/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, last_S)\u001b[0m\n\u001b[1;32m    254\u001b[0m         \"\"\"\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mLsqNonnegF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlast_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(ctx, input, A, last_S)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlsqnonneg_tensor_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_S\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/My Mac (Jamies-Air-2)/Documents/GitHub/NeuralNMF/src/neural_nmf/lsqnonneg_module.py\u001b[0m in \u001b[0;36mlsqnonneg_tensor_version\u001b[0;34m(A, X, last_S)\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m#[s, res] = nnls(A, x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;31m#[s, res] = fnnls(A, x)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfnnls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mP_initial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_initial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m         \u001b[0mres_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "lambd=1e-6\n",
    "optimizer=\"gd\"\n",
    "lr = 1e10\n",
    "\n",
    "epoch = 100\n",
    "class_iters=1\n",
    "weight_decay=0.995\n",
    "\n",
    "loss_func = Energy_Loss_Func(lambd=lambd) \n",
    "\n",
    "all_results = []\n",
    "\n",
    "for _ in range(10):\n",
    "    \n",
    "    start = time()\n",
    "    \n",
    "    net = Neural_NMF([m, k1, k2])\n",
    "\n",
    "    history_supervised = train_unsupervised(net, X, loss_func=loss_func, epoch = epoch, lr = lr, weight_decay=weight_decay, decay_epoch=5, optimizer=optimizer, full_history=True, verbose=True)\n",
    "    \n",
    "    end = time()\n",
    "\n",
    "    print(\"Training time: {}\".format(end-start))\n",
    "    \n",
    "    A1_lst = history_supervised.get('A1')\n",
    "    S1_lst = history_supervised.get('S1')\n",
    "    S2_lst = history_supervised.get('S2')\n",
    "\n",
    "    A2 = history_supervised.get('A2')[-1]\n",
    "\n",
    "    A1 = A1_lst[-1]\n",
    "    S1 = S1_lst[-1]\n",
    "    S2 = S2_lst[-1]\n",
    "\n",
    "\n",
    "    results = {}\n",
    "    results['X'] = X.detach().numpy()\n",
    "    results['Y'] = Y.detach().numpy()\n",
    "    results['A1'] = A1.detach().numpy()\n",
    "    results['S1'] = S1.detach().numpy()\n",
    "    results['A2'] = A2.detach().numpy()\n",
    "    results['S2'] = S2.detach().numpy()\n",
    "    results['words'] = idx_to_word\n",
    "    results['loss'] = np.asarray([float(x) for x in history_supervised.get('loss')])\n",
    "    \n",
    "    all_results.append(results)\n",
    "    \n",
    "np.save(\"unsupervsed_results_all\", all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_unknown_all_1 = 0\n",
    "acc_unknown_all_2 = 0\n",
    "\n",
    "for res in all_results:\n",
    "    A1 = res['A1']\n",
    "    A2 = res['A2']\n",
    "    S1 = res['S1']\n",
    "    S2 = res['S2']\n",
    "    \n",
    "    B = np.multiply(Y_mat.numpy(),L.numpy()) @ np.linalg.pinv(S1)\n",
    "    Y_pred = np.argmax(B @ S1, axis=0)\n",
    "    acc_unknown_1 = Y.numpy()[L[0]==0][Y_pred[L[0]==0]==Y.numpy()[L[0]==0]].shape[0]/ Y[L[0]==0].shape[0]\n",
    "    \n",
    "    acc_unknown_all_1 += acc_unknown_1\n",
    "    \n",
    "    B = np.multiply(Y_mat.numpy(),L.numpy()) @ np.linalg.pinv(S2)\n",
    "    Y_pred = np.argmax(B @ S2, axis=0)\n",
    "    acc_unknown_2 = Y.numpy()[L[0]==0][Y_pred[L[0]==0]==Y.numpy()[L[0]==0]].shape[0]/ Y[L[0]==0].shape[0]\n",
    "    \n",
    "    acc_unknown_all_2 += acc_unknown_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Average layer 1 accuracy...   \", acc_unknown_all_1/10)\n",
    "print(\"Average layer 2 accuracy...   \", acc_unknown_all_2/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S2 = S2_lst[-1]\n",
    "S1 = S1_lst[-1]\n",
    "A2 = history_supervised.get('A2')[-1]\n",
    "\n",
    "A1 = A1_lst[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.multiply(Y_mat.numpy(),L.numpy()) @ torch.pinverse(S2).numpy()\n",
    "\n",
    "Y_pred = np.argmax(B @ S2.detach().numpy(), axis=0)\n",
    "\n",
    "\n",
    "print(\"Accuracy:          {}/{}\".format(Y.numpy()[Y_pred==Y.numpy()].shape[0], Y.shape[0]))\n",
    "print(\"Accuracy known:    {}/{}\".format(Y.numpy()[L[0]==1][Y_pred[L[0]==1]==Y.numpy()[L[0]==1]].shape[0], Y[L[0]==1].shape[0]))\n",
    "print(\"Accuracy unknown:  {}/{}\".format(Y.numpy()[L[0]==0][Y_pred[L[0]==0]==Y.numpy()[L[0]==0]].shape[0], Y[L[0]==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = np.multiply(Y_mat.numpy(),L.numpy()) @ torch.pinverse(S1).numpy()\n",
    "\n",
    "Y_pred = np.argmax(B @ S1.detach().numpy(), axis=0)\n",
    "\n",
    "\n",
    "print(\"Accuracy:          {}/{}\".format(Y.numpy()[Y_pred==Y.numpy()].shape[0], Y.shape[0]))\n",
    "print(\"Accuracy known:    {}/{}\".format(Y.numpy()[L[0]==1][Y_pred[L[0]==1]==Y.numpy()[L[0]==1]].shape[0], Y[L[0]==1].shape[0]))\n",
    "print(\"Accuracy unknown:  {}/{}\".format(Y.numpy()[L[0]==0][Y_pred[L[0]==0]==Y.numpy()[L[0]==0]].shape[0], Y[L[0]==0].shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B1 = Y_mat.numpy() @ torch.pinverse(S1).numpy()\n",
    "Y_pred = np.argmax(B1 @ S1.detach().numpy(), axis=0)\n",
    "print(\"Accuracy: {}/{}\".format(Y.numpy()[Y_pred==Y.numpy()].shape[0], Y.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history_supervised.plot_scalar('loss_nmf')\n",
    "#history_supervised.plot_scalar('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_supervised.plot_scalar('loss_classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_supervised.plot_tensor('S1', [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_supervised.plot_tensor('S2',[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_supervised.plot_tensor('A2', [-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate reconstruction error\n",
    "layer1_error = torch.norm(X - torch.mm(A1, S1))\n",
    "layer2_error = torch.norm(X - torch.mm(torch.mm(A1, A2), S2))\n",
    "\n",
    "print(\"Layer 1 error...    \" + str(layer1_error))\n",
    "print(\"Layer 2 error...    \" + str(layer2_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = np.empty((12,10), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "for i in range(A1.shape[1]):\n",
    "    col = (A1[:,i]*7/6 -  torch.mean(A1, axis=1)).numpy()\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][::-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 10 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(0,5)))\n",
    "print(\"\")\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(5,10)))\n",
    "\n",
    "\n",
    "keywords = np.empty((12,6), dtype=object)\n",
    "\n",
    "for i in range(keywords.shape[1]):\n",
    "    keywords[0,i] = \"Topic \" + str(i+1)\n",
    "    keywords[1,i] = \"-------\"\n",
    "\n",
    "A = torch.mm(A1,A2)\n",
    "for i in range(A.shape[1]):\n",
    "    col = (A[:,i]*7/6 -  torch.mean(A, axis=1)).numpy()\n",
    "    top = col.argsort()\n",
    "    top = top[-10:][::-1]\n",
    "\n",
    "    keywords[2:,i] = idx_to_word[top] \n",
    "\n",
    "print(\"RANK 6 KEYWORDS:\")  \n",
    "print(\"------------------\")\n",
    "col_widths = [max([len(keywords[i][j]) for i in range(keywords.shape[0])])+2 for j in range(keywords.shape[1])]\n",
    "for row in keywords:\n",
    "    print(\"\".join(row[i].ljust(col_widths[i]) for i in range(len(row))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
